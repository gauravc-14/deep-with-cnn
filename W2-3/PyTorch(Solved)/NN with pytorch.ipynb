{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    6000\n",
       "8    6000\n",
       "7    6000\n",
       "6    6000\n",
       "5    6000\n",
       "4    6000\n",
       "3    6000\n",
       "2    6000\n",
       "1    6000\n",
       "0    6000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separating Labels and Features\n",
    "\n",
    "y_train = train['label']\n",
    "x_train = train.drop(['label'], axis = 1)\n",
    "y_test = test['label']\n",
    "x_test = test.drop(['label'], axis = 1)\n",
    "\n",
    "y_train.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   4.,   0.,   0.,   0.,   0.,   0.,  62.,  61.,\n",
       "          21.,  29.,  23.,  51., 136.,  61.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  88.,\n",
       "         201., 228., 225., 255., 115.,  62., 137., 255., 235., 222., 255., 135.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,  47., 252., 234., 238., 224., 215., 215., 229., 108., 180., 207.,\n",
       "         214., 224., 231., 249., 254.,  45.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   1.,   0.,   0., 214., 222., 210., 213., 224., 225., 217.,\n",
       "         220., 254., 233., 219., 221., 217., 223., 221., 240., 254.,   0.,   0.,\n",
       "           1.,   0.,   0.,   0.,   1.,   0.,   0.,   0., 128., 237., 207., 224.,\n",
       "         224., 207., 216., 214., 210., 208., 211., 221., 208., 219., 213., 226.,\n",
       "         211., 237., 150.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,\n",
       "         237., 222., 215., 207., 210., 212., 213., 206., 214., 213., 214., 213.,\n",
       "         210., 215., 214., 206., 199., 218., 255.,  13.,   0.,   2.,   0.,   0.,\n",
       "           0.,   4.,   0.,  85., 228., 210., 218., 200., 211., 208., 203., 215.,\n",
       "         210., 209., 209., 210., 213., 211., 210., 217., 206., 213., 231., 175.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0., 217., 224., 215., 206., 205.,\n",
       "         204., 217., 230., 222., 215., 224., 233., 228., 232., 228., 224., 207.,\n",
       "         212., 215., 213., 229.,  31.,   0.,   4.,   0.,   1.,   0.,  21., 225.,\n",
       "         212., 212., 203., 211., 225., 193., 139., 136., 195., 147., 156., 139.,\n",
       "         128., 162., 197., 223., 207., 220., 213., 232., 177.,   0.,   0.,   0.,\n",
       "           0.,   0., 123., 226., 207., 211., 209., 205., 228., 158.,  90., 103.,\n",
       "         186., 138., 100., 121., 147., 158., 183., 226., 208., 214., 209., 216.,\n",
       "         255.,  13.,   0.,   1.,   0.,   0., 226., 219., 202., 208., 206., 205.,\n",
       "         216., 184., 156., 150., 193., 170., 164., 168., 188., 186., 200., 219.,\n",
       "         216., 213., 213., 211., 233., 148.,   0.,   0.,   0.,  45., 227., 204.,\n",
       "         214., 211., 218., 222., 221., 230., 229., 221., 213., 224., 233., 226.,\n",
       "         220., 219., 221., 224., 223., 217., 210., 218., 213., 254.,   0.,   0.,\n",
       "           0., 157., 226., 203., 207., 211., 209., 215., 205., 198., 207., 208.,\n",
       "         201., 201., 197., 203., 205., 210., 207., 213., 214., 214., 214., 213.,\n",
       "         208., 234., 107.,   0.,   0., 235., 213., 204., 211., 210., 209., 213.,\n",
       "         202., 197., 204., 215., 217., 213., 212., 210., 206., 212., 203., 211.,\n",
       "         218., 215., 214., 208., 209., 222., 230.,   0.,  52., 255., 207., 200.,\n",
       "         208., 213., 210., 210., 208., 207., 202., 201., 209., 216., 216., 216.,\n",
       "         216., 214., 212., 205., 215., 201., 228., 208., 214., 212., 218.,  25.,\n",
       "         118., 217., 201., 206., 208., 213., 208., 205., 206., 210., 211., 202.,\n",
       "         199., 207., 208., 209., 210., 207., 210., 210., 245., 139., 119., 255.,\n",
       "         202., 203., 236., 114., 171., 238., 212., 203., 220., 216., 217., 209.,\n",
       "         207., 205., 210., 211., 206., 204., 206., 209., 211., 215., 210., 206.,\n",
       "         221., 242.,   0., 224., 234., 230., 181.,  26.,  39., 145., 201., 255.,\n",
       "         157., 115., 250., 200., 207., 206., 207., 213., 216., 206., 205., 206.,\n",
       "         207., 206., 215., 207., 221., 238.,   0.,   0., 188.,  85.,   0.,   0.,\n",
       "           0.,   0.,   0.,  31.,   0., 129., 253., 190., 207., 208., 208., 208.,\n",
       "         209., 211., 211., 209., 209., 209., 212., 201., 226., 165.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,  89., 254., 199.,\n",
       "         199., 192., 196., 198., 199., 201., 202., 203., 204., 203., 203., 200.,\n",
       "         222., 155.,   0.,   3.,   3.,   3.,   2.,   0.,   0.,   0.,   1.,   5.,\n",
       "           0.,   0., 255., 218., 226., 232., 228., 224., 222., 220., 219., 219.,\n",
       "         217., 221., 220., 212., 236.,  95.,   0.,   2.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0., 155., 194., 168., 170., 171., 173.,\n",
       "         173., 179., 177., 175., 172., 171., 167., 161., 180.,   0.,   0.,   1.,\n",
       "           0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.]),\n",
       " tensor(2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting DataFrame to Tensor\n",
    "\n",
    "train_x = torch.tensor(x_train.values.astype(np.float32)) \n",
    "train_y = torch.tensor(y_train.values.astype(np.int64))\n",
    "train_x[0], train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.tensor(x_test.values.astype(np.float32))\n",
    "test_y = torch.tensor(y_test.values.astype(np.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data into DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining labels and feature tensor to prepare for DataLoader Function \n",
    "\n",
    "class mydataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.labels = labels\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self,i):\n",
    "        item = self.data[i]\n",
    "        label = self.labels[i]\n",
    "        return (item,label)\n",
    "    \n",
    "training_data = mydataset(train_x,train_y)\n",
    "testing_data = mydataset(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the data into small batches\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size = 100, shuffle = True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequence = nn.Sequential(\n",
    "            nn.Linear(784,100),\n",
    "            nn.BatchNorm1d(num_features = 100), # normalize inputs across all the batches\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), #DropOut minimise the overfitting on training set\n",
    "            nn.Linear(100,64),\n",
    "            nn.BatchNorm1d(num_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,28),\n",
    "            nn.BatchNorm1d(num_features = 28),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(28,10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        output = self.sequence(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs = 100\n",
    "lr_rate = .005\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(),lr = lr_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimiser):\n",
    "    size = len(dataloader.dataset)\n",
    "    train_loss, correct = 0.0, 0\n",
    "    for X, y in dataloader:\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss.item() # Adding loss across all batches\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        correct += ((nn.functional.softmax(pred, dim = 1)).argmax(1) == y).type(torch.float).sum().item()\n",
    "        #Adding Accuracy across all batches\n",
    "        \n",
    "    train_loss /= size #mean of loss\n",
    "    correct /= size  #mean of accuracy     \n",
    "    print(f\"Train Loss: {train_loss:.3f}\")\n",
    "    print(f\"Train Accuracy: {correct:.3f}\")\n",
    "    return train_loss\n",
    "    \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += ((nn.functional.softmax(pred, dim = 1)).argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Loss: {test_loss:.3f}\")\n",
    "    print(f\"Test Accuracy: {correct:.3f}\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== Epoch: 0 ==================]\n",
      "Train Loss: 0.007\n",
      "Train Accuracy: 0.754\n",
      "\n",
      "Test Loss: 0.006\n",
      "Test Accuracy: 0.804\n",
      "[=================== Epoch: 1 ==================]\n",
      "Train Loss: 0.006\n",
      "Train Accuracy: 0.813\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.821\n",
      "[=================== Epoch: 2 ==================]\n",
      "Train Loss: 0.005\n",
      "Train Accuracy: 0.828\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.829\n",
      "[=================== Epoch: 3 ==================]\n",
      "Train Loss: 0.005\n",
      "Train Accuracy: 0.835\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.837\n",
      "[=================== Epoch: 4 ==================]\n",
      "Train Loss: 0.005\n",
      "Train Accuracy: 0.842\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.840\n",
      "[=================== Epoch: 5 ==================]\n",
      "Train Loss: 0.005\n",
      "Train Accuracy: 0.845\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.844\n",
      "[=================== Epoch: 6 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.847\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.847\n",
      "[=================== Epoch: 7 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.850\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.845\n",
      "[=================== Epoch: 8 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.855\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.850\n",
      "[=================== Epoch: 9 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.856\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.847\n",
      "[=================== Epoch: 10 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.857\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.848\n",
      "[=================== Epoch: 11 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.860\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.847\n",
      "[=================== Epoch: 12 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.860\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.849\n",
      "[=================== Epoch: 13 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.862\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.851\n",
      "[=================== Epoch: 14 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.864\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.855\n",
      "[=================== Epoch: 15 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.866\n",
      "\n",
      "Test Loss: 0.005\n",
      "Test Accuracy: 0.849\n",
      "[=================== Epoch: 16 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.867\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.849\n",
      "[=================== Epoch: 17 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.868\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.854\n",
      "[=================== Epoch: 18 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.870\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.858\n",
      "[=================== Epoch: 19 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.871\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.861\n",
      "[=================== Epoch: 20 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.871\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.859\n",
      "[=================== Epoch: 21 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.871\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.856\n",
      "[=================== Epoch: 22 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.872\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.858\n",
      "[=================== Epoch: 23 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.876\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.864\n",
      "[=================== Epoch: 24 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.875\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.860\n",
      "[=================== Epoch: 25 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.877\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.859\n",
      "[=================== Epoch: 26 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.878\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.860\n",
      "[=================== Epoch: 27 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.879\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.862\n",
      "[=================== Epoch: 28 ==================]\n",
      "Train Loss: 0.004\n",
      "Train Accuracy: 0.878\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.860\n",
      "[=================== Epoch: 29 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.880\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.862\n",
      "[=================== Epoch: 30 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.879\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.860\n",
      "[=================== Epoch: 31 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.879\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.862\n",
      "[=================== Epoch: 32 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.880\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.862\n",
      "[=================== Epoch: 33 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.880\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.863\n",
      "[=================== Epoch: 34 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.881\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.857\n",
      "[=================== Epoch: 35 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.881\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.859\n",
      "[=================== Epoch: 36 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.880\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.865\n",
      "[=================== Epoch: 37 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.882\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.864\n",
      "[=================== Epoch: 38 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.884\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.859\n",
      "[=================== Epoch: 39 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.883\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.866\n",
      "[=================== Epoch: 40 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.882\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.861\n",
      "[=================== Epoch: 41 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.884\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.865\n",
      "[=================== Epoch: 42 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.885\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.862\n",
      "[=================== Epoch: 43 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.885\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.867\n",
      "[=================== Epoch: 44 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.886\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.863\n",
      "[=================== Epoch: 45 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.887\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.869\n",
      "[=================== Epoch: 46 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.887\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.860\n",
      "[=================== Epoch: 47 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.887\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.861\n",
      "[=================== Epoch: 48 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.888\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.862\n",
      "[=================== Epoch: 49 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.889\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.860\n",
      "[=================== Epoch: 50 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.886\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.863\n",
      "[=================== Epoch: 51 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.889\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.865\n",
      "[=================== Epoch: 52 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.890\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.864\n",
      "[=================== Epoch: 53 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.889\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.864\n",
      "[=================== Epoch: 54 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.889\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.865\n",
      "[=================== Epoch: 55 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.891\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.867\n",
      "[=================== Epoch: 56 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.892\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.863\n",
      "[=================== Epoch: 57 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.888\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.866\n",
      "[=================== Epoch: 58 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.890\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.863\n",
      "[=================== Epoch: 59 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.893\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.869\n",
      "[=================== Epoch: 60 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.890\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.864\n",
      "[=================== Epoch: 61 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.890\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.864\n",
      "[=================== Epoch: 62 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.893\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.866\n",
      "[=================== Epoch: 63 ==================]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.891\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.866\n",
      "[=================== Epoch: 64 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.894\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.865\n",
      "[=================== Epoch: 65 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.894\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.867\n",
      "[=================== Epoch: 66 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.894\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.865\n",
      "[=================== Epoch: 67 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.893\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.865\n",
      "[=================== Epoch: 68 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.893\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.866\n",
      "[=================== Epoch: 69 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.893\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.863\n",
      "[=================== Epoch: 70 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.895\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.862\n",
      "[=================== Epoch: 71 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.894\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.871\n",
      "[=================== Epoch: 72 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.894\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.864\n",
      "[=================== Epoch: 73 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.895\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.868\n",
      "[=================== Epoch: 74 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.896\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.863\n",
      "[=================== Epoch: 75 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.894\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.862\n",
      "[=================== Epoch: 76 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.896\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.865\n",
      "[=================== Epoch: 77 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.894\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.867\n",
      "[=================== Epoch: 78 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.897\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.869\n",
      "[=================== Epoch: 79 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.898\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.868\n",
      "[=================== Epoch: 80 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.897\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.864\n",
      "[=================== Epoch: 81 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.898\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.862\n",
      "[=================== Epoch: 82 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.896\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.862\n",
      "[=================== Epoch: 83 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.897\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.864\n",
      "[=================== Epoch: 84 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.896\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.865\n",
      "[=================== Epoch: 85 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.900\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.866\n",
      "[=================== Epoch: 86 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.895\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.867\n",
      "[=================== Epoch: 87 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.897\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.866\n",
      "[=================== Epoch: 88 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.897\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.867\n",
      "[=================== Epoch: 89 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.899\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.868\n",
      "[=================== Epoch: 90 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.900\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.863\n",
      "[=================== Epoch: 91 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.898\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.868\n",
      "[=================== Epoch: 92 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.899\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.864\n",
      "[=================== Epoch: 93 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.899\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.865\n",
      "[=================== Epoch: 94 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.899\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.870\n",
      "[=================== Epoch: 95 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.900\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.858\n",
      "[=================== Epoch: 96 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.901\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.867\n",
      "[=================== Epoch: 97 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.900\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.866\n",
      "[=================== Epoch: 98 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.900\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.868\n",
      "[=================== Epoch: 99 ==================]\n",
      "Train Loss: 0.003\n",
      "Train Accuracy: 0.900\n",
      "\n",
      "Test Loss: 0.004\n",
      "Test Accuracy: 0.867\n"
     ]
    }
   ],
   "source": [
    "total_train_loss = []\n",
    "total_test_loss = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"[=================== Epoch: {t} ==================]\")\n",
    "    train_los = train_loop(train_dataloader, model, loss_fn, optimiser)\n",
    "    total_train_loss.append(train_los)\n",
    "    print('')\n",
    "    test_los = test_loop(test_dataloader, model, loss_fn)\n",
    "    total_test_loss.append(test_los)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_train_loss)\n",
    "plt.xlabel(\"No. of Iteration\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for Train-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5527   11   61  129    7    7  224    6   25    3]\n",
      " [   9 5878    7   76   10    1    3    6    4    6]\n",
      " [ 104    6 5171   53  416    6  216    7   16    5]\n",
      " [ 109   28   14 5634  140    7   43    8   10    7]\n",
      " [   9    5  418  204 5123    2  208    2   24    5]\n",
      " [   1    0    0    2    0 5815    0  114    4   64]\n",
      " [1004   10  420  137  322    8 4059    1   34    5]\n",
      " [   0    1    0    0    0   12    0 5866    9  112]\n",
      " [  27    4    5   26    8   17   15   13 5874   11]\n",
      " [   0    0    0    3    0    7    0  219    0 5771]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "y_pred = model(train_x)\n",
    "train_pred = (nn.functional.softmax(y_pred, dim = 1)).argmax(1)\n",
    "print(confusion_matrix(train_y.T, train_pred.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86      6000\n",
      "           1       0.99      0.98      0.98      6000\n",
      "           2       0.85      0.86      0.85      6000\n",
      "           3       0.90      0.94      0.92      6000\n",
      "           4       0.85      0.85      0.85      6000\n",
      "           5       0.99      0.97      0.98      6000\n",
      "           6       0.85      0.68      0.75      6000\n",
      "           7       0.94      0.98      0.96      6000\n",
      "           8       0.98      0.98      0.98      6000\n",
      "           9       0.96      0.96      0.96      6000\n",
      "\n",
      "    accuracy                           0.91     60000\n",
      "   macro avg       0.91      0.91      0.91     60000\n",
      "weighted avg       0.91      0.91      0.91     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_y.T, train_pred.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(train_y.T, train_pred.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for Train-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[876   2  14  20   1   6  71   2   7   1]\n",
      " [  5 981   0   9   2   1   0   1   1   0]\n",
      " [ 28   1 801  21  81   2  56   1   7   2]\n",
      " [ 33  10   7 909  21   4   9   2   4   1]\n",
      " [  2   2  81  38 820   5  47   0   4   1]\n",
      " [  0   1   1   1   0 925   2  41   3  26]\n",
      " [199   3  82  35  77   2 590   0  12   0]\n",
      " [  0   0   0   0   0  10   0 950   0  40]\n",
      " [  6   1   5   4   4   4   7   4 960   5]\n",
      " [  0   0   0   0   0   5   0  60   0 935]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(test_x)\n",
    "test_pred = (nn.functional.softmax(y_pred, dim = 1)).argmax(1)\n",
    "print(confusion_matrix(test_y.T, test_pred.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82      1000\n",
      "           1       0.98      0.98      0.98      1000\n",
      "           2       0.81      0.80      0.80      1000\n",
      "           3       0.88      0.91      0.89      1000\n",
      "           4       0.82      0.82      0.82      1000\n",
      "           5       0.96      0.93      0.94      1000\n",
      "           6       0.75      0.59      0.66      1000\n",
      "           7       0.90      0.95      0.92      1000\n",
      "           8       0.96      0.96      0.96      1000\n",
      "           9       0.92      0.94      0.93      1000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y.T, test_pred.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(test_y.T, test_pred.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
